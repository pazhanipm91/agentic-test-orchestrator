# agentic-test-orchestrator
LLM reasons about API behavior, failures, and improvements

## Supports OpenAI + Local LLMs (Ollama / Llama3 / Mistral) for enterprise environments.
# Swap OpenAI with Ollama endpoint
OLLAMA_URL = "http://localhost:11434/api/generate"

```markdown
## ğŸ§  Confidence Scoring & Self-Healing

The system assigns a confidence score to each failure analysis generated by the LLM.
Low-confidence failures trigger autonomous test regeneration, while high-confidence
failures are surfaced for human review.

ğŸ“ Implementation:
- agents/confidence_scorer.py
- engine/retry_controller.py

## ğŸš€ Agentic API Testing Framework
An autonomous system that moves beyond static test cases to reasoned API reliability.

ğŸ§  The Architecture: Plannerâ€“Executorâ€“Evaluator
Unlike traditional automation, this system utilizes a multi-agent loop:

Planner: Analyzes OpenAPI specifications to determine critical paths.

Generator: Produces executable pytest code.

Executor: Runs tests in a deterministic environment.

Analyzer (The "Brain"): If a test fails, the LLM performs a root-cause analysis to distinguish between a "flaky test" and a "real API bug."

ğŸ› ï¸ Key Features
Self-Healing Loop: Automatically suggests test updates when API contracts change.

LLM Failure Reasoning: Detailed classification of errors (e.g., Logic vs. Infrastructure).

Local LLM Support: Fully compatible with Ollama (Llama3/Mistral) for secure, enterprise environments.

ğŸš€ Getting Started
Clone the repo: git clone https://github.com/pazhanipm91/agentic-api-testing.git

Install deps: pip install -r requirements.txt

Add your key to .env: OPENAI_API_KEY=your_key_here
